---
title: "Sorption project"
author: "Kseniya Belousova, Natalya Jakubson, Natalya Bogatyreva, Darja Nikitina, Alexander Sokolov"
date: "15 12 2021"
output: word_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      error = FALSE,
                      warning = FALSE,
                      cache = FALSE,
                      fig.height = 10,
                      fig.width = 10)


library(tidyverse)
library(flextable)
library(readxl)
library(CBCgrps)
library(GGally)
library(tidymodels)
library(ggcorrplot)
library(Hmisc)
library(rpart.plot) 
library(treeheatr)
library(caret) 
library(mlr)
library(gridExtra)
library(ggpubr)
library(ggfortify)
library(pROC)

```

# Read xlsx file

```{r}

df <- read_excel('data/sorbtion_v1_enc.xlsx')

df%>%
  glimpse()

```

# Let's bring the variables to a convenient type.

```{r}
df%>%
  mutate(across(c(Timing_of_the_disease, Intem_A10_before, Intem_A10_after, Intem_A20_before, Intem_A20_after, Intem_MCF_before, Intem_MCF_after), function(x) as.numeric(x)))%>%
  mutate(across(c(ID, CT_scan, Outcome), function(x) as.factor(x)))->data_with_all_cols

data_with_all_cols%>%
  glimpse()

```

# Let's calculate the difference between the quantitative variables "before" and "after"

```{r}

data_with_all_cols[,grepl(".*before", names(data_with_all_cols))]-
  data_with_all_cols[,grepl(".*after", names(data_with_all_cols))]->data_difference

data_difference%>%
  set_names(paste0("difference_", strsplit(names(data_difference), "_before")))->data_difference_renamed
```

# Let's combine everything into a final dataframe 
```{r}
data_with_all_cols_and_diff <- cbind(data_with_all_cols, data_difference_renamed)

```

# Let's see how many missing values the quantitative variables have
```{r}

data_with_all_cols_and_diff%>%
  summarise_all(function(x) (sum(is.na(x))/length(x))%>%round(4)%>%`*`(100))%>%
  pivot_longer(everything())%>%
  rename(Percentage_of_missing_values=value, Variable = name)-> NAs_table

```

# For further work, we will select only those columns where less than 10% of the missing values, the result will be saved to the variable "data". We will also replace the outcome 1,2 with "survive" or "died".

```{r}

data_with_all_cols_and_diff%>%
  select(NAs_table$Variable[NAs_table$Percentage_of_missing_values<10])->data

levels(data$Outcome) <- c("Survived", "Died")


```

# Descriptive tables for quantitative variables

```{r}

stats <- list(
  '_max'=function(x) max(x, na.rm=TRUE)%>%as.character(),
  '_min' = function(x) min(x, na.rm = TRUE)%>%as.character(),
  '_mean' = function(x) mean(x, na.rm = TRUE)%>%round(2)%>%as.character(),
  '_95%_CI_for_mean' = function(x) t.test(x, na.rm = TRUE)%>%.$conf%>%as.numeric()%>%round(2)%>%str_c(collapse = " ," ),
  '_standard_deviation' = function(x) sd(x, na.rm = TRUE)%>%round(2)%>%as.character(),
  '_median' = function(x) median(x, na.rm = TRUE)%>%round(2)%>%as.character(),
  '_quantile_0.25' = function(x) quantile(x, 0.25, na.rm = TRUE, names = FALSE)%>%round(2)%>%as.character(),
  '_quantile_0.75' = function(x) quantile(x, 0.75, na.rm = TRUE, names = FALSE)%>%round(2)%>%as.character(),
  '_IQR' = function(x) (quantile(x, 0.75, na.rm = TRUE, names = FALSE)-quantile(x, 0.25, na.rm = TRUE, names = FALSE))%>%round(2)%>%as.character(),
  '_number_of_values' = function(x) length(x)%>%as.character(),
  '_number_of_NA' = function(x) sum(is.na(x))%>%as.character()
  
  
)

data%>%
  group_by(Outcome)%>%
  summarise(across(where(is.numeric), stats))%>%
  pivot_longer(!Outcome)%>%
  separate(name, into=c("variable","parameter"), sep="__")->num_table_grouped

```

# A table for evaluating categorical variables (let's see how many patients we have with different degrees of CT_scan and outcomes)

```{r}

function_cat <- function(data, var){
  data%>%
    count(.data[[var]])%>%
    mutate(perc_abs = (n/sum(n))%>%round(4)%>%`*`(100)%>%paste0(.,"%"))%>%
    rename('value'=var,
           'count'=n,
           'sample percentage' = perc_abs)
}

data%>%
  select(where(is.factor) & !ID)%>%names()%>%set_names()%>%
  map(function(x) function_cat(data, x))%>%
  enframe()%>%unnest(cols = c(value))%>%rename('variable'=name)->categorical_table


```


# Distribution of variables (histograms)


```{r}

histogramming <- function(data, var){
  ggplot(data, aes(x = .data[[var]]))+
    geom_histogram(bins = 20, fill="white", color = "red", na.rm = TRUE)
}

data%>%
  select(where(is.numeric))%>%
  names()%>%set_names()%>%
  map(function(x) histogramming(data, x))

```

# Boxplots 


```{r}
ggbox_plotting <-  function(data, var){
  
  ggboxplot(data, x = "Outcome", y = var,
                color = "black", fill = "Outcome", outlier.shape = NA, title = var, na.rm=T)+
  stat_compare_means(method = "wilcox.test", na.rm = TRUE)
  
}

data%>%
  select(where(is.numeric))%>%
  names()%>%set_names()%>%
  map(function(x) ggbox_plotting(data, x))



```

# Violinplots

```{r}

violin_plotting <- function(data, var) {
  
  ggplot(data, aes(x = Outcome, y = .data[[var]])) +
    geom_violin(color = "darkgreen",
                fill = "lightgreen", alpha= .3, na.rm = TRUE) +
    geom_boxplot(fill = "green",
                 width = 0.1, na.rm = TRUE, outlier.shape = NA)+
    theme_classic()+
    scale_y_continuous(limits = quantile(data[[var]], c(0.05, 0.95), na.rm = TRUE))+
    coord_cartesian(ylim = quantile(data[[var]], c(0.05, 0.95), na.rm = TRUE))
    
}


data%>%
  select(where(is.numeric))%>%names()%>%set_names()%>%
  map(function(x) violin_plotting(data, x))

```

# Barplot for CT_scan degrees divided by outcomes

```{r}

ggplot(data, aes(x = CT_scan, fill = Outcome)) +
  geom_bar(position = "dodge") +
  theme_classic()

```

# Heatmap for normalized values of quantitative variables "before" and "after"

```{r}
data%>%
  select(ends_with("before"))%>%as.matrix()%>%heatmap(scale="column", Colv = NA, Rowv = NA)

data%>%
  select(ends_with("after"))%>%as.matrix()%>%heatmap(scale="column", Colv = NA, Rowv = NA)

```

# Heatmap for difference

```{r}
data%>%
  select(starts_with("difference"))%>%as.matrix()%>%heatmap(scale="column", Colv = NA, Rowv = NA)

```

# Let's compare quantitative variables grouped by outcomes

```{r}

data%>%
  select(!c(ID, Sorption_start_date)) ->data_multigroup

group_char <- multigrps(data.frame(data_multigroup), 
                        gvar = "Outcome", 
                        tabNA = "ifany", 
                        pnormtest = 1, 
                        sim = TRUE,
                        p.rd = 6)


colnames(group_char) <- c("Variable", "All_patients", "Survived", "Died", "p-value")

group_char%>%
  mutate(across(c(`p-value`), function(x)  as.numeric(x)))%>%
  mutate(p_adjust = p.adjust(`p-value`, method = "holm"))->group_char_adj

group_char_adj%>%
  select(Variable, p_adjust)%>%filter(p_adjust<0.05)
```
**Based on the results of comparison by groups , a significant difference between groups is determined for: LDG before and after, for D-dimer after, IL-6 difference, CT degrees**

```{r}

group_char_adj%>%
  flextable()%>%
  theme_box()%>%
  width(., width = 1)%>%
    width(.,j = 5, width = 0.5)%>%
    width(.,j = 1, width = 2)%>%
    align(align = "center", part = "header")

```

# For further work, we will replace the missing values with the median

```{r}

data%>%
  mutate(across(where(is.numeric), function(x) ifelse (is.na(x), median(x, na.rm = TRUE), x)))->data

```

# Log-transformation for D-dimer before and after, CRP after, PCT after and before, IL-6 after and before, IL-18 after and before

```{r}
data%>%
  mutate(across (c(Procalcitonin_before, Procalcitonin_after,
                   CRP_before, CRP_after, D_dimer_before, D_dimer_after, IL_18_before, IL_18_after, IL_6_before, IL_6_after), function(x) log(x)))->data_with_log

```

# Histigrams for data_with_log

```{r}

data_with_log%>%
  select(where(is.numeric))%>%
  names()%>%set_names()%>%
  map(function(x) histogramming(data_with_log, x))

```

# ggpairs plot

```{r}

ggpairs(data_with_log[8:22], aes(alpha = .25), 
        lower = list(continuous = 'smooth_lm'))
```

# Correlation for variables "before", "after", "difference".

#For variables "before"

```{r}

data%>%
  select(c(Age,Timing_of_the_disease)| (ends_with("before") & !starts_with("difference")))%>%
  psych::corr.test(method = "spearman")->corr_data_before

corr_data_before$r%>%
  ggcorrplot(p.mat = corr_data_before$p, lab=TRUE, title = "Spearman's correlation for variables BEFORE")

```

**Correlation is determined for IL-18 and IL-6 0.51, LDH and ferritin 0.39**



# For variables "after".

```{r}
data%>%
  select(c(Age,Timing_of_the_disease)| ends_with("after"))%>%
  psych::corr.test(method = "spearman")->corr_data_after

corr_data_after$r%>%
  ggcorrplot(p.mat = corr_data_after$p, lab=TRUE, title = "Spearman's correlation for variables AFTER")
```

**A low correlation is determined for IL-18 after and IL-6 after 0.41, CRP after and PCT after 0.34, LDH after and D-dimer after 0.33**


# For "difference"

```{r}
data%>%
  select(c(Age,Timing_of_the_disease)| (starts_with("difference")))%>%
  psych::corr.test(method = "spearman")->corr_data_difference

corr_data_difference$r%>%
  ggcorrplot(p.mat = corr_data_difference$p, lab=TRUE, title = "Spearman's correlation for variables DIFFERENCE")

```

**Correlation is determined for the difference between IL-6 and IL-18 0.54.**



# For all variables

```{r}

data%>%
  select(!c(ID, Sorption_start_date, Day_in_hospital)& where(is.numeric))%>%
  psych::corr.test(method = "spearman")->corr_data

corr_data$r%>%
  ggcorrplot(p.mat = corr_data$p, lab=TRUE, title="Spearman's correlation for all variables")
```


# Next, we will make a decision tree, before that we will remove unnecessary variables

```{r}
data["ID"] <- NULL
data["Sorption_start_date"] <- NULL
```


#First let's see if our dataset is balanced

```{r}

response.column = 'Outcome'
response = data[[response.column]]
table(response)

```

# Separation into training and test samples

```{r}

index <- sample(2, nrow(data), prob = c(0.8, 0.2), replace = TRUE)
index 

train_base <- data[index==1, ] # Train data
test_base <- data[index ==2, ] # Test data
```

# Balance of outcomes in training and test samples

```{r}

table(train_base$Outcome)
table(test_base$Outcome)
```

# The model of the decision tree on the training sample.

```{r}

Outcome_model <- rpart(formula = Outcome ~., 
                        data = train_base, 
                        method = "class")
summary(Outcome_model)

```

# Visualization of the decision tree

```{r}

rpart.plot(x = Outcome_model, yesno = 2, 
           fallen.leaves = TRUE, clip.right.labs = FALSE)

x <- partykit::as.party(Outcome_model)
heat_tree(x = x)

```

# On a test sample

```{r}

class_predicted <- predict(object = Outcome_model,  
                           newdata = test_base,   
                           type = "class")
confusionMatrix(data = class_predicted,       
                reference = test_base$Outcome)
heat_tree(
  x = x,
  data_test = test_base)

```
# Next, we will make different models using the caret package.

# Logistic regression with caret package

# Separation into training and test samples

```{r}

set.seed(124)

partition_index = createDataPartition(response, p = 0.8, list = FALSE)
train_caret = data[partition_index, ]
test_caret = data[-partition_index, ]


```

# Balance of outcomes in training and test samples

```{r}

table(train_caret$Outcome)
table(test_caret$Outcome)

```
# Logistic regression model

```{r}

model_glm_for_outcome <- caret::train(Outcome ~., data = train_caret,
                          method = "glm",
                          metric = "ROC",
                          tuneLength = 10,
                          trControl = trainControl(method = "cv", number = 10,
                                                   classProbs = T, summaryFunction = twoClassSummary),
                          preProcess = c("center","scale", "pca"))

model_glm_for_outcome
summary(model_glm_for_outcome)
```

# CART tree

```{r}
model_rpart_outcome <- caret::train(Outcome ~., data = train_caret,
                            method = "rpart",
                            metric = "ROC",
                            tuneLength = 20,
                            trControl = trainControl(method = "cv", number = 10,
                                                     classProbs = T, summaryFunction = twoClassSummary))

```

```{r}
plot(model_rpart_outcome)
model_rpart_outcome
rpart.plot::rpart.plot(model_rpart_outcome$finalModel, type = 2, 
                       fallen.leaves = T, extra = 2, cex = 0.70)



```

# Random forest
# mtry=16, min.node.size=1, splitrule=extratrees
```{r}
tgrid <- expand.grid(
  .mtry = 3,
  .splitrule = "extratrees",
  .min.node.size = 1
)


model_forest_for_outcome <- caret::train(Outcome ~., data = train_caret,
                             method = "ranger",
                             metric = "ROC",
                             trControl = trainControl(method = "cv", number = 10,
                                                      classProbs = T, summaryFunction = twoClassSummary), tuneGrid = tgrid,
                             preProcess = c("center","scale","pca"))

model_forest_for_outcome

```

# Compare our models (on train dataset)
```{r}

model_list <- list(Random_Forest = model_forest_for_outcome, Logistic_Regression = model_glm_for_outcome, Rpart_Tree = model_rpart_outcome)

resamples <- resamples(model_list)

bwplot(resamples, metric="ROC")

```

# Try on the test set

# Random forest on the test set

```{r}
pred_rf <- predict(model_forest_for_outcome, test_caret)

# Confusion Matrix 

cm_rf <- confusionMatrix(pred_rf, test_caret$Outcome, positive= "Died")


# Prediction Probabilities


pred_prob_rf <- predict(model_forest_for_outcome, test_caret, type="prob")

# ROC value


roc_rf <- roc(test_caret$Outcome, pred_prob_rf$Died)

# Confusion Matrix for Random Forest Model

cm_rf

caTools::colAUC(pred_prob_rf$Died, test_caret$Outcome, plotROC = T)
```

# Logistic regression on the test set

```{r}

# prediction on Test data set

pred_glm <- predict(model_glm_for_outcome, test_caret)

# Confusion Matrix 

cm_glm <- confusionMatrix(pred_glm, test_caret$Outcome, positive="Died")

# Prediction Probabilities
pred_prob_glm <- predict(model_glm_for_outcome, test_caret, type="prob")

# ROC value
roc_glm <- roc(test_caret$Outcome, pred_prob_glm$Died)


# Confusion matrix 
cm_glm

# ROC curve

caTools::colAUC(pred_prob_glm$Died, test_caret$Outcome, plotROC = T)


```

# Rpart CART on the test set

```{r}
# prediction on Test data set
pred_rpart <- predict(model_rpart_outcome, test_caret)
# Confusion Matrix 
cm_rpart <- confusionMatrix(pred_rpart, test_caret$Outcome, positive="Died")

# Prediction Probabilities
pred_prob_rpart <- predict(model_rpart_outcome, test_caret, type="prob")
# ROC value
roc_rpart <- roc(test_caret$Outcome, pred_prob_rpart$Died)

# Confusion matrix 
cm_rpart

# ROC curve

caTools::colAUC(pred_prob_rpart$Died, test_caret$Outcome, plotROC = T)

```



# Result random forest

```{r}
result_rf <- c(cm_rf$byClass['Sensitivity'], cm_rf$byClass['Specificity'], cm_rf$byClass['Precision'], 
               cm_rf$byClass['Recall'], cm_rf$byClass['F1'], roc_rf$auc)

```

# Result logistic regression

```{r}

result_glm <- c(cm_glm$byClass['Sensitivity'], cm_glm$byClass['Specificity'], cm_glm$byClass['Precision'], 
                cm_glm$byClass['Recall'], cm_glm$byClass['F1'], roc_glm$auc)

```

# Result rpart

```{r}
result_rpart <- c(cm_rpart$byClass['Sensitivity'], cm_rpart$byClass['Specificity'], cm_rpart$byClass['Precision'], 
                  cm_rpart$byClass['Recall'], cm_rpart$byClass['F1'], roc_rpart$auc)


```

# Common result

```{r}
all_results <- data.frame(rbind(result_rf, result_glm, result_rpart))

names(all_results) <- c("Sensitivity", "Specificity", "Precision", "Recall", "F1", "AUC")

all_results




```



# PCA

```{r}
#PCA

data_PCA <- data 
    
data_PCA %>%
  select(where(is.numeric)) -> num

dif <- as.data.frame(c(num[1:3], num[19:25]))

pca_res_dif <- prcomp(dif, scale = T)

autoplot(pca_res_dif,
         data = dif) +
  theme_bw()

dif_factor <- cbind(data[4:5], dif)

```


```{r}
autoplot(pca_res_dif,
         data = dif_factor,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         loadings.label.size=3,
         frame = F, frame.type = 'convex') +
  theme_bw()

```


```{r}
# The percentage of the variance explained is not very high, even the 3 main components give only 50 %:
pc_var <- pca_res_dif$sdev^2
pc_var

# PVE - Proportion of Variance Explained ----
pc_pve <- pc_var / sum(pc_var)
pc_pve
cumsum(pc_pve)

# plot(pca_res_dif, type = "l")
plot(pc_pve, type = "b", main = "Proportion of Variance Explained")
plot(cumsum(pc_pve), type = "b", main = "Cumulative Proportion of Variance Explained")
```


```{r}
autoplot(pca_res_dif,
         data = dif_factor,
         size = 1,
         colour = 'CT_scan',
         loadings = T,
         loadings.label = T,
         loadings.label.size=3,
         frame = F, frame.type = 'norm') +
  theme_bw()

 
```

```{r}
# Let's see which variables need to be Log-transformed.
ggpairs(dif)
```

```{r}
#PCA, removed the time factors and achieved a slightly better explanation of the variance by the main components:

dif_wo_time <- num[19:25]

pca_res_dif_wo_time <- prcomp(dif_wo_time, scale = T)

# autoplot(pca_res_dif,
#          data = dif) +
#   theme_bw()

dif_factor_wo_time <- cbind(data[4:5], dif_wo_time)

autoplot(pca_res_dif_wo_time,
         data = dif_factor_wo_time,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         frame = F, frame.type = 'convex') +
  theme_bw()
```

```{r}
pc_var <- pca_res_dif$sdev^2


# PVE - Proportion of Variance Explained ----
pc_pve <- pc_var / sum(pc_var)


# plot(pca_res_dif, type = "l")
plot(pc_pve, type = "b", main = "Proportion of Variance Explained")
plot(cumsum(pc_pve), type = "b", main = "Cumulative Proportion of Variance Explained")
```

```{r}
iflog <- function(x) ifelse(x>=0, log(x), log(-x))  

lgdd <- as.data.frame(iflog(data_PCA$difference_D_dimer))

data_PCA_lg <- (cbind(data_PCA, lgdd))

data_PCA_lg %>%
  select(where(is.numeric)) -> num_lg

#  ggpairs(dif_lg) #D-dimer after log-transformation

dif_lg <- as.data.frame(c(num_lg[1:3], num_lg[19:24], num_lg[26]))

pca_res_dif_lg <- prcomp(dif_lg, scale = T)

# autoplot(pca_res_dif_lg,
#          data = dif_lg) +
#   theme_bw()

dif_factor_lg <- cbind(data[4:5], dif_lg)

autoplot(pca_res_dif_lg,
         data = dif_factor_lg,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         frame = F, frame.type = 'convex') +
  theme_bw()


```
```{r}

pca_res_dif_lg <- prcomp(dif_lg, scale = F)

dif_factor_lg <- cbind(data[4:5], dif_lg)

autoplot(pca_res_dif_lg,
         data = dif_factor_lg,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         loadings.label.size = 2,
         frame = T, frame.type = 'convex') +
  theme_bw()


```


```{r}
# data_PCA_lg <- data_PCA %>%
#   mutate(lgdd  = ifelse(difference_D_dimer>=0, log10(difference_D_dimer), log10(-difference_D_dimer)))  
# 
# data_PCA_lg %>%
#   select(where(is.numeric)) -> num_lg
# 
# # ggpairs(dif_lg) #проверим, как прологарифмировался Д-димер
# 
# dif_lg <- as.data.frame(c(num_lg[1:3], num_lg[19:24], num_lg[26]))
# 
# pca_res_dif_lg <- prcomp(dif_lg, scale = F)
# 
# dif_factor_lg <- cbind(data[4:5], dif_lg)
# 
# autoplot(pca_res_dif_lg,
#          data = dif_factor_lg,
#          size = 3,
#          colour = 'Outcome',
#          loadings = T,
#          loadings.label = T,
#          frame = T, frame.type = 'convex') +
#   theme_bw()

```


```{r}
# Here I just remind you that I tried PCA with data before/after, and not with a decrease in laboratory parameters, but I did not get clustering of outcomes.

data_PCA_bef <- data %>%
  select('CT_scan', 'Outcome', ends_with("before"))
 
    
data_PCA_bef %>%
  select(where(is.numeric)) -> num_bef

all_bef <- as.data.frame(c(num[1:3], num_bef))

pca_res_bef <- prcomp(num_bef, scale = T)
pca_res_all_bef <- prcomp(all_bef, scale = T)

# autoplot(pca_res_bef,
#          data = num_bef) +
#   theme_bw()
# 
# autoplot(pca_res_all_bef,
#          data = all_bef) +
#   theme_bw()

bef_factor <- cbind(data[4:5], num_bef)
all_bef_factor <- cbind(data[4:5], all_bef)

autoplot(pca_res_bef,
         data = bef_factor,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         loadings.label.size = 2,
         frame = T, frame.type = 'convex') +
  theme_bw()

autoplot(pca_res_all_bef,
         data = all_bef_factor,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         loadings.label.size = 2,
         frame = T, frame.type = 'convex') +
  theme_bw()


```
```{r}
# Here I just remind you that I tried PCA with data before/after, and not with a decrease in laboratory parameters, but I did not get clustering of outcomes.

data_PCA_aft <- data %>%
  select('CT_scan', 'Outcome', ends_with("after"))

data_PCA_aft %>%
  select(where(is.numeric)) -> num_aft

all_aft <- as.data.frame(c(num[1:3], num_aft))

pca_res_aft <- prcomp(num_aft, scale = T)
pca_res_all_aft <- prcomp(all_aft, scale = T)

# autoplot(pca_res_bef,
#          data = num_bef) +
#   theme_bw()
# 
# autoplot(pca_res_all_bef,
#          data = all_bef) +
#   theme_bw()

aft_factor <- cbind(data[4:5], num_aft)
all_aft_factor <- cbind(data[4:5], all_aft)

autoplot(pca_res_aft,
         data = aft_factor,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         loadings.label.size = 2,
         frame = T, frame.type = 'convex') +
  theme_bw()

autoplot(pca_res_all_aft,
         data = all_aft_factor,
         size = 1,
         colour = 'Outcome',
         loadings = T,
         loadings.label = T,
         loadings.label.size = 2,
         frame = T, frame.type = 'convex') +
  theme_bw()


```



















